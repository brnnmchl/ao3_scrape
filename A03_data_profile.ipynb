{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating profile for: /Users/brinnamichael/Desktop/Grad School/Illinois/Spring 2019/Open Data Mashups/opendatamashups/data/Fanfiction/AO3/code/../data/csv/.DS_Store, /Users/brinnamichael/Desktop/Grad School/Illinois/Spring 2019/Open Data Mashups/opendatamashups/data/Fanfiction/AO3/code/../data/csv/AO3_DW_20190421.csv, /Users/brinnamichael/Desktop/Grad School/Illinois/Spring 2019/Open Data Mashups/opendatamashups/data/Fanfiction/AO3/code/../data/csv/AO3_ALL_20190421.csv, /Users/brinnamichael/Desktop/Grad School/Illinois/Spring 2019/Open Data Mashups/opendatamashups/data/Fanfiction/AO3/code/../data/csv/AO3_DG_20190421.csv, /Users/brinnamichael/Desktop/Grad School/Illinois/Spring 2019/Open Data Mashups/opendatamashups/data/Fanfiction/AO3/code/../data/csv/AO3_TD_20190421.csv, /Users/brinnamichael/Desktop/Grad School/Illinois/Spring 2019/Open Data Mashups/opendatamashups/data/Fanfiction/AO3/code/../data/csv/AO3_JT_20190421.csv, /Users/brinnamichael/Desktop/Grad School/Illinois/Spring 2019/Open Data Mashups/opendatamashups/data/Fanfiction/AO3/code/../data/csv/AO3_SB_20190421.csv\n",
      "\n",
      "/Users/brinnamichael/Desktop/Grad School/Illinois/Spring 2019/Open Data Mashups/opendatamashups/data/Fanfiction/AO3/code/documentation created\n",
      "\n",
      "Profiles written into /Users/brinnamichael/Desktop/Grad School/Illinois/Spring 2019/Open Data Mashups/opendatamashups/data/Fanfiction/AO3/code/documentation\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brinnamichael/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:150: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/brinnamichael/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "# command line prompt\n",
    "# python data_profile.py -[mh][source folder of data] [target folder for profiles]\n",
    "# -m make markdown\n",
    "# -h make html\n",
    "\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "# import markdown # removed html output for now\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# this wasn't being used!!!!!!\n",
    "# def getFiles(path):\n",
    "#     \"\"\"Function to return a list of all files within a folder\"\"\"\n",
    "#     files = [f for f in os.listdir(path) if isfile(join(path, f)) and f[0] != '.']\n",
    "#     p = Path(path)\n",
    "#     print(glob.glob(p.read_text() / \"*\"))\n",
    "#     print('hello')\n",
    "#     return files\n",
    "\n",
    "\n",
    "def basic_stats(file):\n",
    "    stats = os.stat(file)\n",
    "    size = stats.st_size\n",
    "    last_modified = datetime.datetime.fromtimestamp(stats.st_mtime).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    last_access = datetime.datetime.fromtimestamp(stats.st_atime).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return {'filename': str(file.absolute()), 'size': size, 'last_access': last_access, 'last_modified': last_modified}\n",
    "\n",
    "\n",
    "def review_csv(file, mode='rt', headers=True, index_row=True, missing=''):\n",
    "    with open(file, mode) as fin:\n",
    "        fin = csv.reader(fin)\n",
    "        if headers:\n",
    "            col_names = next(fin)\n",
    "            data = [r for r in fin]\n",
    "        else:\n",
    "            data = [r for r in fin]\n",
    "\n",
    "    if index_row:\n",
    "        ids = [r[0] for r in data]\n",
    "    else:\n",
    "        ids = \"None declared\"\n",
    "\n",
    "    num_rows = len(data)\n",
    "    data = list(map(list, zip(*data)))\n",
    "\n",
    "    num_columns = len(col_names)\n",
    "    col_info = {'csv_basic': {'num_rows': num_rows, 'num_columns': num_columns, 'missing': missing}, 'cols': {}}\n",
    "    for i, col in enumerate(col_names):\n",
    "\n",
    "        info = {}\n",
    "        num_uniques = len(set(data[i]))\n",
    "        info['unique_values'] = str(num_uniques) + \" (this includes missing values)\"\n",
    "        if num_uniques <= 10:\n",
    "            uvals = set(data[i])\n",
    "            uval_print = []\n",
    "            for x in uvals:\n",
    "                if x == missing:\n",
    "                    uval_print.append(\"[missing code]\")\n",
    "                else:\n",
    "                    uval_print.append(x)\n",
    "            uval_print.sort() # sorting unique values for pretty printing\n",
    "            info['unique_value_content'] = \"The values are:\\n\\t* \" + \"\\n\\t* \".join(uval_print)\n",
    "        else:\n",
    "            info['unique_value_content'] = \"Not reported (More than 10 unique values)\"\n",
    "        info['missing'] = data[i].count(missing)\n",
    "        info['percent_missing'] = \"{:.0%}\".format(info['missing'] / len(data[i]))\n",
    "        # digits = len([d for d in data[i] if d.isdigit()])\n",
    "        # dcount = 0\n",
    "        passed_digits = []\n",
    "        for d in data[i]:\n",
    "            try:\n",
    "                d = float(d)\n",
    "                # dcount += 1\n",
    "                passed_digits.append(float(d))\n",
    "            except:\n",
    "                # this is fine becasue this is simply testing\n",
    "                # if it can be done at all\n",
    "                # stop fretting, elizabeth.\n",
    "                pass # passed_digits.append('failed to convert to float')\n",
    "        digits = len(passed_digits)\n",
    "        totalvalues = len([d for d in data[i] if len(d) > 0])\n",
    "\n",
    "        if totalvalues == 0:\n",
    "            info['percent_digit'] = \"no digits\"\n",
    "        else:\n",
    "            info['percent_digit'] = \"{:.0%}\".format(digits / totalvalues)\n",
    "\n",
    "        if digits > 0:\n",
    "            # digit_values = [float(d) for d in data[i] if d.isdigit()]\n",
    "            info['min_digit'] = min(passed_digits)\n",
    "            info['max_digit'] = max(passed_digits)\n",
    "        else:\n",
    "            info['min_digit'] = \"no digits\"\n",
    "            info['max_digit'] = \"no digits\"\n",
    "        if headers:\n",
    "            col_info['cols'][col] = info\n",
    "        else:\n",
    "            col_info['cols']['col_' + str(i)] = info\n",
    "    return col_info\n",
    "\n",
    "\n",
    "def make_md(file_name, file_data, headers, target):\n",
    "    # print(file_name, headers, target)\n",
    "    dt = '{:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now())\n",
    "    md = \"\"\n",
    "    md += \"Data Profile for \" + file_name.name + \"\\n\\n\"\n",
    "    md += \"Generated on: \" + dt + \"\\n\"\n",
    "    md += \"\\n\\n\"\n",
    "    basic = file_data['csv_basic']\n",
    "    md += \"* Number of columns: \" + str(basic['num_columns']) + \"\\n\"\n",
    "    md += \"* Number of rows: \" + str(basic['num_rows']) + \"\\n\"\n",
    "    if basic['missing'] == '':\n",
    "        missing_print = \"(empty string)\"\n",
    "    else:\n",
    "        missing_print = basic['missing']\n",
    "    md += \"* Using missing value of: \" + missing_print + \"\\n\"\n",
    "    md += \"\\n\"\n",
    "    info = [file_data['columns'] for f in file_data.keys()][0]\n",
    "    for key in headers:\n",
    "        data = info[key]\n",
    "        md += \"**\" + key + \"**\" + \"\\n\"\n",
    "        md += \"-\" * (len(key) + 2) + \"\\n\"\n",
    "        md += \"* Description of column: (you fill in)\\n\"\n",
    "        md += \"* Collection methods: (you fill in)\\n\"\n",
    "        md += \"* Description of data values and units: (you fill in)\\n\"\n",
    "        md += \"* Reason for missing values: (you fill in)\\n\"\n",
    "        # md += \"\\n\"\n",
    "        for column, val in data.items():  # go through all the data info\n",
    "            md += \"* \" + column.replace('_', ' ').capitalize() + \": \" + str(val) + \"\\n\"\n",
    "        md += \"\\n\"\n",
    "    # print file_name\n",
    "    write_name = file_name.stem + '_DataProfile.md'\n",
    "    # write_name = file_name.split('/')[-1].split('.')[0] + '_DataProfile'\n",
    "    # print write_name\n",
    "    with open(target.absolute() / write_name, 'wt') as fout:\n",
    "        fout.write(md)\n",
    "\n",
    "    # the html looks like crap\n",
    "    # with open(target + write_name + '.html', 'wt') as fout:\n",
    "    #     fout.write(markdown.markdown(md))\n",
    "\n",
    "\n",
    "def get_headers(file):\n",
    "    with open(file, 'rU') as fin:\n",
    "        fin = csv.reader(fin)\n",
    "        headers = next(fin)\n",
    "    return headers\n",
    "\n",
    "\n",
    "def main(source, target, missingcode):\n",
    "    do_not_write = False\n",
    "    target = Path(target)\n",
    "    source = Path(source)\n",
    "    # if not target.is_dir():\n",
    "    #     target += \"/\"  # sorry windows\n",
    "    # files = [source + f for f in getFiles(source)]\n",
    "    if source.is_dir():\n",
    "        # if not source.endswith('/'):\n",
    "        #     source += \"/\"\n",
    "        files = [p.absolute() for p in source.glob('*')]\n",
    "        num_files = len(files)\n",
    "    elif source.is_file():\n",
    "        files = [source.absolute()]  # forcing this into a list of 1 so for loop works\n",
    "        num_files = 1\n",
    "\n",
    "    # only report out file names if there are <10 to do\n",
    "    if num_files < 10:  # change this number if you care\n",
    "        print(\"Generating profile for: \" + \", \".join([str(p) for p in files]))\n",
    "    else:\n",
    "        print(\"Generating profiles for \" + str(num_files) + \" files\")\n",
    "\n",
    "    if os.path.isdir(target):  # this will not play nicely with windows...\n",
    "        confirm_needed = True\n",
    "        tstr = str(target.absolute())\n",
    "        while confirm_needed:\n",
    "            confirm_overwrite = input(\"\\n\" + tstr + \" already exists. Do you want to overwrite? (Y/N)\\n\").upper()\n",
    "            print(confirm_overwrite)\n",
    "            if confirm_overwrite == \"Y\":\n",
    "                confirm_needed = False\n",
    "                print(\"Profiles written into \" + tstr + \"\\n\")\n",
    "            elif confirm_overwrite == \"N\":\n",
    "                do_not_write = True\n",
    "                print(\"Profiles not written.\\n\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Input not understood. Please try again.\")\n",
    "    else:\n",
    "        target.mkdir()  # but I can't test windows right now...\n",
    "        print(\"\\n\" + str(target.absolute()) + \" created\")\n",
    "        print(\"\\nProfiles written into \" + str(target.absolute()) + \"\\n\")\n",
    "    all_file_data = {}\n",
    "\n",
    "    if not do_not_write:\n",
    "        for f in files:\n",
    "            f = Path(f)\n",
    "            if f.suffix == '.csv':\n",
    "                finfo = basic_stats(f)\n",
    "                headers = get_headers(f)\n",
    "                csvinfo = review_csv(f, mode='rU', missing=missingcode)\n",
    "                all_file_data[str(f.name)] = ({'file_metadata': finfo,\n",
    "                                     'csv_basic': csvinfo['csv_basic'],\n",
    "                                     'columns': csvinfo['cols']})\n",
    "                make_md(f, all_file_data[str(f.name)], headers, target)\n",
    "        write_name = str(target.stem + '_DataProfiles.json')\n",
    "        # write_name = target.split('/')[-2].split('.')[0] + '_DataProfiles.json'\n",
    "        with open(target.absolute() / write_name, 'wt') as jsonout:\n",
    "            json.dump(all_file_data, jsonout, indent=4)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # print args\n",
    "    # ['data_profile.py', 'vagrants/', 'vagrant-profiles/', '']\n",
    "    # usage\n",
    "    # python data_profile.py source output_folder (missing_code)\n",
    "    # source may be file or folder\n",
    "    # output must be a folder\n",
    "    # missing code optional, will presume empty string if not provided\n",
    "    source = \"../data/csv\" # existing folder or file here\n",
    "    target = \"documentation\" # name the new folder where the results should go\n",
    "    missing_code = \"\" #provide the missing data code\n",
    "\n",
    "    # main(source, target, kind, missingcode)\n",
    "    main(source, target, missing_code)\n",
    "    # not dealing with the the mode right now, just letting it make both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
